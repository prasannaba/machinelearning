"""
    f(x) is the cost function or loss function, it is a function that returns
    the difference between actual/expected and estimated value calculated from 
    parameters generated by the data with assumpution like Least Square, Logistic or
    customized expression...
    Actual value is the actual value we have in training data, for example values of y
    Expected value is the anticipated values of y from test/field data based on our experience from past data.

    In linear regression, y is the actual value, & w.x+b is the estimated value based on the
    parameters w & b from the data x. But how to find the w & b from the data?
    To find the w & b from the data, we use the optimization algorithms, where
    we try to minimize the loss or maximize the returns if the function is inverse of loss function.

    Optimization -> is finding the parameters that minimizes the lose/maximize the returns,
    that is, the difference between the actual/expected value & estimated value. So that our
    estimated value is close to the actual/expected value.
    Optimization is at what value of the parameters say w & b, (y-w.x+b) is minimum. This happens
    when the derivative of loss function with respect to w & b is set to zero, logically it 
    means the value of w & b at which rate of change of w & b with respect to y-w.x+b is zero or almost zero.
    This means difference y & w.x+b is almost zero or near to zero. This is called algorithm convergence.

    Roots are -> At what value/s of x, f(x) is zero

    Find minima of a function using gradient descent algorithm & scipy optimize module
    Find roots of a function using Newton-Raphson 

    Author: Prasanna Badami

"""
# %%

# In practice in most cases we don't have to worry about building our own cost_function 
# also called as loss function when we select a classifier or model like Linear 
# Classifer/Logistic Regression/Gaussian Models/ Kernel Methods/PCA that take 
# data and gives us the model parameters for example here x_current.
# Loss functions are built inside the classifer/model. 
# We need to set the hyper parameters like iterations, precision, initial guess.

# But having the knowledge of cost/loss function & gradient descent helps us 
# to create our own models when on the shelf models doesn't fit our requirement.

# This is a reverse process, we are defining a loss function & verifying that 
# gradient descent works.
# Loss function is the function of difference between actual value & estimated value.
# When we say cost/loss function is x**2-7x then it means on an average the difference is 
# x**2-7x between actual value & estimated value. Keep this in mind.
# x is nothing but w in loss function. We are passing current value of w in every iteration to find the minima.
# L(w) = w**2-7w
# derivative of L(w) = 2w-7 = 0, therefore w = 3.5
# Minima of loss function L(w) occurs at w = 3.5
# %%
from random import randint
import numpy as np
from scipy import optimize
from scipy.misc import derivative
from matplotlib import pyplot as plt

# %%
def cost_function(x):
    return(x**2-7*x-3)
# %%
# Code to find optimization of cost function using gradient descent
learning_rate = 0.1
precision = 0.000001
maxiter = 1000
x_current = 0 # initial guess
diff_results = 1
i = 0
errors = []
while (diff_results > precision and i < maxiter):
    x_previous = x_current
    x_current = x_current - learning_rate * derivative(cost_function, x0=x_current)
    diff_results = abs(x_current - x_previous)
    errors.append(diff_results)
    i = i + 1
    print(f'x_current: {x_current:0.5f} at iteration: {i}')

errors = np.array(errors)
print(f'Minima of loss function occurs at x={x_current:0.5f}')
print(f'Function value at minima:{cost_function(x_current)}')
plt.plot(range(i), errors)
plt.show()
# %%
# optimization of cost function using minimze function - single line :)
optimize.minimize(cost_function, x0=0.01)
# %%
def jacobian(x):
    return(2*x+7)
# Newton optimizer is different from Newton-Raphson root finding algorithm.
optimize.minimize(cost_function, x0=0.1, method='Newton-CG', jac=jacobian)
# %%
results = optimize.minimize_scalar(cost_function)
results.success
results.x, results
# %%
# plot the cost_function(x) vs x
x = np.linspace(1, 6, 100)
y = cost_function(x)
fig, ax = plt.subplots()
ax.set_ylabel('Loss Function L(w)')
ax.set_xlabel('w')
ax.set_title('Cost/Loss Function L(w) vs. w')
ax.plot(x, y)

# %%
fig = plt.figure()
ax = fig.add_subplot(121)
ax.set_ylabel('Loss Function L(w)')
ax.set_xlabel('w')
ax.set_title('Cost/Loss Function L(w) vs. w')
ax.plot(x, y)
# y = x**2 + 5
# plt.plot(x, y)

# %%
# Let's check this cost function: x1**2 + 2*x2
fun = lambda x: x[0]**2 - 2*x[1]
# fun([2, 2])
optimize.minimize(fun, x0=[0.1, 0.1])

# %%
# Roots of cost function, works only for positive real roots
optimize.newton(cost_function, x0=0.5)
# %%
# Roots of a function
def func_root(x):
    return(x**2-9)
optimize.newton(func_root, x0=0.1)
# %%
# finding roots of a polynomial, complex also..
# x**2+0*x-9
coeff = [1, 0, -9]
np.roots(coeff)
# %%
# Root of a function
optimize.newton(func_root, x0=0.5)

# %%
# Manual Newton-Raphson Method
function_one = lambda x: x**2-81
guess_root=1
expected_precision=0.01
estimated_precision=1
count_iterations = 0
while estimated_precision > expected_precision :
    current_root = guess_root - \
        function_one(guess_root)/derivative(function_one, guess_root)
    estimated_precision = abs(current_root-guess_root)
    guess_root = current_root
    count_iterations += 1

print(f'The root of function is {current_root:0.2f}, \
    \nTotal iterations took: {count_iterations}')
# %%
x2 = np.arange(1, 21)
np.random.seed(40)
x3 = 2 * x2 + 2.5 * np.random.randn(20)
print(x3)
# %%
plt.scatter(x2[1], x3)
# %%
